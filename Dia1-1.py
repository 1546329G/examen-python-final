#ğŸ§  PARTE 1: MLP con Scikit-learn

from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import confusion_matrix, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Cargar el dataset
digits = load_digits()
X, y = digits.data, digits.target

# 2. Dividir datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Crear el modelo MLP
mlp = MLPClassifier(hidden_layer_sizes=(64,), activation='relu', solver='adam', max_iter=5)

# 4. Entrenar
mlp.fit(X_train, y_train)

# 5. Predecir
y_pred = mlp.predict(X_test)

# 6. Evaluar
acc = accuracy_score(y_test, y_pred)
print("Accuracy:", acc)

# 7. Matriz de confusiÃ³n
cm = confusion_matrix(y_test, y_pred)

# 8. Graficar
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Matriz de ConfusiÃ³n MLP")
plt.xlabel("PredicciÃ³n")
plt.ylabel("Real")
plt.show()













# ğŸ§  PARTE 1: MLP con Scikit-learn

from sklearn.datasets import load_digits  # ğŸ“¥ Carga un dataset de imÃ¡genes de dÃ­gitos escritos a mano (del 0 al 9)
from sklearn.model_selection import train_test_split  # ğŸ”€ Sirve para dividir los datos en entrenamiento y prueba
from sklearn.neural_network import MLPClassifier  # ğŸ§  Importa el modelo PerceptrÃ³n Multicapa (MLP)
from sklearn.metrics import confusion_matrix, accuracy_score  # ğŸ“Š Funciones para evaluar el modelo
import matplotlib.pyplot as plt  # ğŸ“ˆ LibrerÃ­a para graficar
import seaborn as sns  # ğŸ¨ LibrerÃ­a para graficar mÃ¡s bonito (usa colores y cuadrÃ­culas)

# 1. Cargar el dataset
digits = load_digits()  # ğŸ“¥ Cargamos los datos y los guardamos en una variable llamada 'digits'
X, y = digits.data, digits.target  # ğŸ”£ X = imÃ¡genes en forma de nÃºmeros (64 columnas), y = nÃºmero real (de 0 a 9)

# 2. Dividir datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# ğŸ§ª Divide los datos:
#  - 80% para entrenar (X_train, y_train)
#  - 20% para probar (X_test, y_test)
#  - random_state=42 hace que la divisiÃ³n sea siempre igual (para repetir resultados)

# 3. Crear el modelo MLP
mlp = MLPClassifier(hidden_layer_sizes=(64,), activation='relu', solver='adam', max_iter=5)
# ğŸ§  Creamos el modelo MLP (Red neuronal simple)
# - hidden_layer_sizes=(64,) â†’ 1 capa oculta con 64 neuronas
# - activation='relu' â†’ FunciÃ³n que activa las neuronas
# - solver='adam' â†’ Algoritmo que optimiza el aprendizaje
# - max_iter=5 â†’ Entrena por 5 Ã©pocas (pocas veces para que sea rÃ¡pido)

# 4. Entrenar
mlp.fit(X_train, y_train)  # ğŸ”§ Entrena el modelo con los datos de entrenamiento

# 5. Predecir
y_pred = mlp.predict(X_test)  # ğŸ¯ El modelo intenta adivinar los nÃºmeros del conjunto de prueba

# 6. Evaluar
acc = accuracy_score(y_test, y_pred)  # âœ… Compara las predicciones con los valores reales
print("Accuracy:", acc)  # ğŸ–¨ï¸ Muestra el porcentaje de aciertos

# 7. Matriz de confusiÃ³n
cm = confusion_matrix(y_test, y_pred)  # ğŸ” Muestra los aciertos y errores por clase (ej. cuÃ¡ntos 2 confundiÃ³ con 3)

# 8. Graficar
plt.figure(figsize=(8, 6))  # ğŸ–¼ï¸ TamaÃ±o del grÃ¡fico
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')  # ğŸ“Š Dibuja la matriz con nÃºmeros y color
plt.title("Matriz de ConfusiÃ³n MLP")  # TÃ­tulo del grÃ¡fico
plt.xlabel("PredicciÃ³n")  # Eje X
plt.ylabel("Real")  # Eje Y
plt.show()  # ğŸ‘€ Muestra la figura
